---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-"
  )
```

# evalITR

<!-- badges: start -->
<!-- badges: end -->

## Installation

You can install the development version of evalITR from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("MichaelLLi/evalITR")
```


(Optional) if you have multiple cores, we recommendate using multisession futures and processing in parallel. This would increase computation efficiency and reduce the time to fit the model. 

```r
library(furrr)
library(future.apply)

nworkers <- 4
plan(multisession, workers =nworkers)
```


## Example under cross-validation

This is an example using the `star` dataset (for more information about the dataset, please use `?star`). 

We first load the dataset and specify both outcome variables (reading, math, and writing scores) and
covariates we want to include in the model. Then we use a series of machine learning
algorithms to estimate the heterogeneous effects of small classes on
educational attainment. We use 20% as a budget constraint and tuned the
model through through the 3-fold cross validation.

```{r message = FALSE}
library(tidyverse)
library(evalITR)

load("data/star.rda")

# specifying outcomes
outcomes <- c("g3tlangss")

# specifying covariates
covariates <-  star %>% 
                dplyr::select(-c("g3tlangss",
                "g3treadss","g3tmathss","treatment")) %>% 
                colnames()

# train the model
fit_cv <- run_itr(outcome = outcomes,
               treatment = "treatment",
               covariates = covariates,
               data = star,
               algorithms = c(
                  "causal_forest", 
                  "bart",
                  "lasso",
                  "boost", 
                  "random_forest",
                  "bagging",
                  "cart"),
               plim = 0.2,
               n_folds = 3,
               ngates = 3)
```

```{r estimates}
# compute estimates
est_cv <- estimate_itr(fit_cv)
```

```{r summary}
# summarize estimates
summary(est_cv)
```

The`summary()` function displays the following summary statistics: (1) population average prescriptive effect `PAPE`; (2) population average prescriptive effect with a budget constraint `PAPEp`; (3) population average prescriptive effect difference with a budget constraint `PAPDp`; (4) and area under the prescriptive effect curve `AUPEC`. For more information about these evaluation metrics, please refer to [this paper](https://arxiv.org/abs/1905.05389).


We plot the estimated Area Under the Prescriptive Effect Curve
for the writing score across a range of budget constraints for different algorithms.

```{r plot, fig.width=8, fig.height=6,fig.align = "center"}
# plot the AUPEC with different ML algorithms
plot(est_cv)


```
## Example under sample splitting

Please set argument input of `n_folds` to 0 ion order to train the models under sample splitting. The split ratio between train and test set is determined by the `ratio` argument. 
```{r message = FALSE}
library(tidyverse)
library(evalITR)

load("data/star.rda")

# specifying outcomes
outcomes <- c("g3tlangss")

# specifying covariates
covariates <-  star %>% 
                dplyr::select(-c("g3tlangss",
                "g3treadss","g3tmathss","treatment")) %>% 
                colnames()

# estimate ITR 
fit <- run_itr(outcome = outcomes,
               treatment = "treatment",
               covariates = covariates,
               data = star,
               algorithms = c(
                  "causal_forest", 
                  "lasso",
                  "boost", 
                  "random_forest",
                  "bagging",
                  "cart"),
               plim = 0.2,
               ngates = 3,
               ratio = 0.67)
```
```{r cv_estimates}
# compute estimates
est <- estimate_itr(fit)
```

```{r cv_summary}
# summarize estimates
summary(est)
```

```{r cv_plot, fig.width=8, fig.height=6,fig.align = "center"}
# plot the AUPEC with different ML algorithms
plot(est)

```