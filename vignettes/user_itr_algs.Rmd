---
title: "Compare Estimated and User Defined ITR"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{user_itr_algs}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "../man/figures/README-"
  )

library(dplyr)
library(evalITR)

load("../data/star.rda")

# specifying the outcome
outcomes <- "g3tlangss"

# specifying the treatment
treatment <- "treatment"

# specifying the data (remove other outcomes)
star_data <- star %>% dplyr::select(-c(g3treadss,g3tmathss))

# specifying the formula
user_formula <- as.formula(
  "g3tlangss ~ treatment + gender + race + birthmonth + 
  birthyear + SCHLURBN + GRDRANGE + GKENRMNT + GKFRLNCH + 
  GKBUSED + GKWHITE ")

```

###  Estimated vs. User Defined ITR

The package allows to compare the performance of estimated ITRs with user defined ITRs. The `estimate_itr` function takes the following arguments:

| Argument | Description              |
|:-------- | :------------------------|
| `fit`    | a fitted object from the `estimate_itr` function |
| `user_itr` | a function defined by users that returns a unit-level continuous score for treatment assignment (we assume those that have score less than 0 should not have treatment) |
| `data`   | a data frame   |
| `treatment` | a character string specifying the treatment variable in the `data` |
| `outcome` | a character string specifying the outcome variable in the `data` |
| `budget` | a numeric value specifying the maximum percentage of population that can be treated under the budget constraint |


The function returns an object that contains the estimated GATE, ATE, and AUPEC for the user defined ITR.

```{r compare_itr_summary, warning = FALSE, message = FALSE}

# estimate ITR 
fit <- estimate_itr(
  treatment = treatment,
  form = user_formula,
  data = star_data,
  algorithms = c("causal_forest"),
  budget = 0.2,
  split_ratio = 0.7)

# user's own ITR
score_function <- function(data){
  score <- (data$GKWHITE)/5
  return(score)
}

# evalutate ITR
compare_itr <- evaluate_itr(
  fit = fit,
  user_itr = score_function,
  data = star_data,
  treatment = treatment,
  outcome = outcomes,
  budget = 0.2)

# summarize estimates
summary(compare_itr)
```

We plot the estimated Area Under the Prescriptive Effect Curve (AUPEC) for the writing score across a range of budget constraints for user defined ITR and estimated ITRs. The plot shows that the estimated ITRs have better performance than the user defined ITR.

```{r compare_itr_aupec, fig.width = 6, fig.height = 4}
# plot the AUPEC 
plot(compare_itr)
```


### Existing Model vs. User-Defined Model

The package also allows to compare the performance of estimated ITRs of existing ML packages with user defined models. The following code shows an example using causal forest from the `grf` package with sample splitting. The `estimate_itr` function takes the following arguments:

| Argument | Description              |
|:-------- | :------------------------|
| `treatment` | a character string specifying the treatment variable in the `data` |
| `form`   | a formula specifying the outcome and covariates |
| `data`   | a data frame   |
| `algorithms` | a character vector specifying the ML algorithms to be used |
| `budget` | a numeric value specifying the maximum percentage of population that can be treated under the budget constraint |
| `split_ratio` | a character string specifying the outcome variable in the `data` |
| `user_model` | a character string specifying the user defined model |


```{r compare_itr_model_summary, warning = FALSE, message = FALSE}

# user's own model
user_model <- function(data){
  model <- lm(Y ~ T*(GKWHITE + GKBUSED + GKFRLNCH), data = data)
  return(model)
  }

# estimate ITR
compare_fit <- estimate_itr(
  treatment = treatment,
  form = user_formula,
  data = star_data,
  algorithms = c("causal_forest"),
  budget = 0.2,
  split_ratio = 0.7,
  user_model = "user_model")


# evaluate ITR 
compare_est <- evaluate_itr(compare_fit)

# summarize estimates
summary(compare_est)
plot(compare_est)
```